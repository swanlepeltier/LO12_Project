{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6cbb91",
   "metadata": {},
   "source": [
    "# Analyse des habitudes d'achat Steam avec l'algorithme Apriori\n",
    "\n",
    "Ce notebook accompagne un projet d'analyse de données Steam, utilisant l'algorithme Apriori pour extraire des règles d'association et générer des recommandations de jeux. Nous passerons par les étapes suivantes :\n",
    "\n",
    "1. **Importation des bibliothèques**\n",
    "2. **Téléchargement et chargement des données depuis KaggleHub**\n",
    "3. **Prétraitement et nettoyage**\n",
    "4. **Construction des transactions**\n",
    "5. **Extraction des itemsets fréquents et génération des règles**\n",
    "6. **Génération de règles au format CLIPS**\n",
    "7. **Test interactif des règles CLIPS**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd31cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# 1. Import des bibliothèques\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import kagglehub  # interface personnalisée pour Kaggle\n",
    "import clips      # API Python pour CLIPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0afea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Télécharger et charger les données Steam\n",
    "\n",
    "Dans cette section, nous téléchargeons le jeu de données « @tamber/steam-video-games » depuis KaggleHub et le chargeons dans un DataFrame pandas. Nous vérifions également l'intégrité du fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759c46e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "def load_steam_data(dataset_name: str = \"tamber/steam-video-games\",\n",
    "                    file_name: str = \"steam-200k.csv\") -> pd.DataFrame:\n",
    "    # Téléchargement via KaggleHub\n",
    "    path = kagglehub.dataset_download(dataset_name)\n",
    "    print(f\"Dataset téléchargé dans : {path}\")\n",
    "\n",
    "    # Construction du chemin vers le fichier et vérification\n",
    "    file_path = os.path.join(path, file_name)\n",
    "    if not os.path.exists(file_path) or os.path.getsize(file_path) < 1000:\n",
    "        raise FileNotFoundError(f\"Fichier introuvable ou corrompu : {file_path}\")\n",
    "\n",
    "    # Lecture du CSV sans en-tête, avec noms de colonnes personnalisés\n",
    "    col_names = ['user_id', 'game_name', 'purchase', 'playtime', 'unused']\n",
    "    df = pd.read_csv(file_path,\n",
    "                     encoding='latin-1',\n",
    "                     delimiter=',',\n",
    "                     header=None,\n",
    "                     names=col_names)\n",
    "\n",
    "    print(\"Aperçu des données Steam (5 premières lignes) :\")\n",
    "    display(df.head())\n",
    "    return df\n",
    "\n",
    "# Chargement des données\n",
    "steam_df = load_steam_data()\n",
    "print(f\"Nombre total de lignes initiales : {len(steam_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48fe748",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Prétraitement et nettoyage des données\n",
    "\n",
    "Nous conservons uniquement les colonnes `user_id` et `game_name`, supprimons les doublons et retirons la colonne inutilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c194fba7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # On garde uniquement les colonnes d'intérêt et on supprime les doublons\n",
    "    df = df[['user_id', 'game_name']]\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "# Application du prétraitement\n",
    "clean_df = preprocess_data(steam_df)\n",
    "print(f\"Nombre de lignes après nettoyage : {len(clean_df)}\")\n",
    "display(clean_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e34b2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Construction des transactions pour l'algorithme Apriori\n",
    "\n",
    "Nous groupons les jeux par utilisateur pour obtenir une liste de transactions, où chaque transaction représente l'ensemble des jeux d'un utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92101ea2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "def build_transactions(df: pd.DataFrame) -> list:\n",
    "    grouped = df.groupby('user_id')['game_name'].apply(list)\n",
    "    return grouped.tolist()\n",
    "\n",
    "transactions = build_transactions(clean_df)\n",
    "print(f\"Nombre de transactions : {len(transactions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a09df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Extraction des itemsets fréquents et génération des règles d'association\n",
    "\n",
    "Nous convertissons les transactions en matrice binaire, appliquons l'algorithme Apriori pour extraire les itemsets fréquents, puis générons les règles d'association avec un seuil de confiance minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c2e7a5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "def mine_association_rules(transactions: list,\n",
    "                           min_support: float = 0.02,\n",
    "                           min_confidence: float = 0.5) -> pd.DataFrame:\n",
    "    # Encodage des transactions au format binaire\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    trans_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    # Extraction des itemsets fréquents\n",
    "    frequent_itemsets = apriori(trans_df,\n",
    "                                min_support=min_support,\n",
    "                                use_colnames=True)\n",
    "\n",
    "    # Génération des règles d'association\n",
    "    rules = association_rules(frequent_itemsets,\n",
    "                               metric=\"confidence\",\n",
    "                               min_threshold=min_confidence)\n",
    "    return rules\n",
    "\n",
    "# Extraction des règles avec support >= 2% et confiance >= 60%\n",
    "rules = mine_association_rules(transactions,\n",
    "                               min_support=0.02,\n",
    "                               min_confidence=0.6)\n",
    "print(f\"Nombre de règles générées : {len(rules)}\")\n",
    "display(rules.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c59df5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Génération des règles au format CLIPS\n",
    "\n",
    "Pour utiliser CLIPS, nous convertissons les noms de jeux en symboles compatibles et écrivons les règles simples (1 antécédent → 1 conséquent) dans un fichier `.clp`. Nous pouvons également ajouter des faits de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e63be1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "def sanitize(name: str) -> str:\n",
    "    # Remplace les caractères spéciaux par des underscores\n",
    "    name = re.sub(r\"[&()/\\-]\", \" \", name)\n",
    "    name = re.sub(r\"[^a-zA-Z0-9]\", \"_\", name)\n",
    "    name = re.sub(r\"_+\", \"_\", name).strip(\"_\")\n",
    "    return name\n",
    "\n",
    "\n",
    "def generate_clips_rules(rules: pd.DataFrame,\n",
    "                          output_file: str = \"regles_steam.clp\",\n",
    "                          max_antecedents: int = 1,\n",
    "                          max_consequents: int = 1,\n",
    "                          test_items: list = None) -> None:\n",
    "    if test_items is None:\n",
    "        test_items = []\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, row in rules.iterrows():\n",
    "            antecedents = list(row['antecedents'])\n",
    "            consequents = list(row['consequents'])\n",
    "\n",
    "            # Filtre pour règles simples\n",
    "            if len(antecedents) != max_antecedents or len(consequents) != max_consequents:\n",
    "                continue\n",
    "\n",
    "            ant = sanitize(antecedents[0])\n",
    "            cons = sanitize(consequents[0])\n",
    "            f.write(f\"(defrule regle-{i+1}\\n\")\n",
    "            f.write(f\"  (achat {ant})\\n\")\n",
    "            f.write(\"  =>\\n\")\n",
    "            f.write(f\"  (assert (achat {cons}))\\n\")\n",
    "            f.write(f\"  (printout t \\\"Regle activée : {ant} => {cons}\\\" crlf))\\n\\n\")\n",
    "\n",
    "        # Ajout des cas de test si fournis\n",
    "        if test_items:\n",
    "            f.write(\"(deffacts cas-test\\n\")\n",
    "            for item in test_items:\n",
    "                f.write(f\"  (achat {sanitize(item)})\\n\")\n",
    "            f.write(\")\\n\")\n",
    "\n",
    "    print(f\"Fichier CLIPS généré : {output_file}\")\n",
    "\n",
    "# Génération du fichier de règles\n",
    "generate_clips_rules(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ac142",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Test interactif des règles CLIPS\n",
    "\n",
    "Nous chargeons le fichier `.clp` dans l'environnement CLIPS, puis proposons un test interactif permettant à l'utilisateur d'entrer un jeu et d'observer les recommandations générées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061dce6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# Initialisation de l'environnement CLIPS\n",
    "environment = clips.Environment()\n",
    "environment.load(\"regles_steam.clp\")\n",
    "\n",
    "# Fonction de test interactif\n",
    "\n",
    "def clips_test():\n",
    "    environment.reset()\n",
    "    jeu_test = input(\"Entrez le nom du jeu à tester (ex : HalfLife): \")\n",
    "    environnement.assert_string(f\"(achat {sanitize(jeu_test)})\")\n",
    "    environment.run()\n",
    "\n",
    "    # Affichage des faits résultants\n",
    "    for fact in environment.facts():\n",
    "        print(fact)\n",
    "\n",
    "# Boucle de test\n",
    "try:\n",
    "    clips_test()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Fin du test interactif.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
